{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Using TensorFlow backend.\n"
     ]
    }
   ],
   "source": [
    "import os\n",
    "import re\n",
    "import itertools\n",
    "import pickle\n",
    "from collections import Counter,defaultdict\n",
    "try:\n",
    "\timport pandas as pd\n",
    "\timport numpy as np\n",
    "\tfrom nltk.corpus import stopwords\n",
    "\tfrom nltk.stem import PorterStemmer\n",
    "\timport gensim\n",
    "\tfrom gensim.models import Word2Vec\n",
    "\tfrom nltk.stem import WordNetLemmatizer\n",
    "\tfrom keras.utils import np_utils\n",
    "except:\n",
    "\tprint(\"require modules: keras,gensim,nltk.stem,nltk.corpus,nltk.stem, please install it.\")\n",
    "\texit()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "reg1 = re.compile(\"\\.txt$\")\n",
    "reg2 = re.compile(\"([0-9]+)\\.txt\")\n",
    "reg3 = re.compile(\".*_([0-9])\\.txt\")\n",
    "reg4 = re.compile(\"\\[.+\\]\")\n",
    "reg5 = re.compile(\"info\\.txt\")\n",
    "lyrics_dic = {}\n",
    "#iter all directory and load all song(txt file)\n",
    "for i in os.listdir():\n",
    "    if os.path.isdir(i):\n",
    "        for path,sub,items in os.walk(i):\n",
    "            if any([reg1.findall(item) for item in items]):\n",
    "                for item in items:\n",
    "                    if reg5.findall(item):\n",
    "                        continue\n",
    "                    if reg3.findall(item):\n",
    "                        num = [\"0\"+reg3.findall(item)[0]]\n",
    "                        name = \"_\".join(path.split(\"/\") + num)\n",
    "                    else:\n",
    "                        name = \"_\".join(path.split(\"/\") + reg2.findall(item))\n",
    "\n",
    "                    with open(os.path.join(path,item),\"r\",encoding=\"utf8\", errors='ignore') as f:\n",
    "                        lyrics = \"\".join(f.readlines())\n",
    "                        lyrics = reg4.subn(\"\",lyrics)[0]\n",
    "                        lyrics_dic[name] = lyrics"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "777"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(lyrics_dic.keys())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "df=pd.DataFrame(columns=[\"lyrics\",\"mood\"])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "for key in lyrics_dic.keys():\n",
    "    #print(key)\n",
    "    if \"Happy\" in key:\n",
    "        \n",
    "        df=df.append({\"lyrics\":lyrics_dic[key],\"mood\":\"1\"},ignore_index=True)\n",
    "    elif \"Sad\" in key:\n",
    "        df=df.append({\"lyrics\":lyrics_dic[key],\"mood\":\"2\"},ignore_index=True)\n",
    "    elif \"Angry\" in key:\n",
    "        df=df.append({\"lyrics\":lyrics_dic[key],\"mood\":\"3\"},ignore_index=True)\n",
    "    elif \"Relaxed\" in key:\n",
    "        df=df.append({\"lyrics\":lyrics_dic[key],\"mood\":\"4\"},ignore_index=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>lyrics</th>\n",
       "      <th>mood</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>Put your lips close to mine\\nAs long as they d...</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>My lullaby,hung out to dry\\nWhat's up with tha...</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>Though you've played at love and lost\\nAnd sor...</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>we know we are the ones\\nwho do it numb again\\...</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>Another day has come and gone\\nThey fade away ...</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                              lyrics mood\n",
       "0  Put your lips close to mine\\nAs long as they d...    1\n",
       "1  My lullaby,hung out to dry\\nWhat's up with tha...    1\n",
       "2  Though you've played at love and lost\\nAnd sor...    1\n",
       "3  we know we are the ones\\nwho do it numb again\\...    1\n",
       "4  Another day has come and gone\\nThey fade away ...    1"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "df = df.sample(frac=1).reset_index(drop=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 81,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_new=pd.read_csv(\"df_mood_backup.csv\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 128,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>lyrics</th>\n",
       "      <th>mood</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>600</th>\n",
       "      <td>You should have listened to what mama said\\nAn...</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>601</th>\n",
       "      <td>Spoken Intro:\\nYou ever want something\\nThat y...</td>\n",
       "      <td>2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>602</th>\n",
       "      <td>All the world's a masquerade\\nMade up of fools...</td>\n",
       "      <td>2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>603</th>\n",
       "      <td>Chains of despair cloacked by darkness\\nThe th...</td>\n",
       "      <td>3</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>604</th>\n",
       "      <td>One more night\\nOne more night\\n\\nI've been tr...</td>\n",
       "      <td>2</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                                lyrics  mood\n",
       "600  You should have listened to what mama said\\nAn...     1\n",
       "601  Spoken Intro:\\nYou ever want something\\nThat y...     2\n",
       "602  All the world's a masquerade\\nMade up of fools...     2\n",
       "603  Chains of despair cloacked by darkness\\nThe th...     3\n",
       "604  One more night\\nOne more night\\n\\nI've been tr...     2"
      ]
     },
     "execution_count": 128,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df_new.tail()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 83,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_new=df_new[[\"lyrics\",\"mood\"]]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 84,
   "metadata": {},
   "outputs": [],
   "source": [
    "df3=df.append(df_new,ignore_index=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 85,
   "metadata": {},
   "outputs": [],
   "source": [
    "df3[\"mood\"]=df3[\"mood\"].apply(str)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 91,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(1382, 2)"
      ]
     },
     "execution_count": 91,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df3.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 93,
   "metadata": {},
   "outputs": [],
   "source": [
    "set(df3[\"mood\"].values)\n",
    "df=df3"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 107,
   "metadata": {},
   "outputs": [],
   "source": [
    "data_X = df['lyrics'].values\n",
    "data_Y = df['mood'].values\n",
    "import nltk\n",
    "import string\n",
    "import re\n",
    "\n",
    "porter_stemmer = nltk.stem.porter.PorterStemmer()\n",
    "def porter_tokenizer(text, stemmer=porter_stemmer):\n",
    "    lower_txt = text.lower()\n",
    "    tokens = nltk.wordpunct_tokenize(lower_txt)\n",
    "    stems = [porter_stemmer.stem(t) for t in tokens]\n",
    "    no_punct = [s for s in stems if re.match('^[a-zA-Z]+$', s) is not None]\n",
    "    return no_punct\n",
    "from sklearn.feature_extraction.text import TfidfVectorizer\n",
    "tfidf = TfidfVectorizer(\n",
    "            encoding='utf-8',\n",
    "            decode_error='replace',\n",
    "            strip_accents='unicode',\n",
    "            analyzer='word',\n",
    "            binary=False,\n",
    "            stop_words=\"english\",\n",
    "            tokenizer=porter_tokenizer\n",
    "    )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 108,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "\n",
    "\n",
    "data_X = tfidf.fit_transform(data_X)\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 121,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.model_selection import train_test_split\n",
    "X_train, X_test, y_train, y_test = train_test_split(data_X, data_Y, test_size=0.4, random_state=0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 122,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[[93 50  2 22]\n",
      " [46 98 15 37]\n",
      " [17 29 25  8]\n",
      " [21 56  3 31]]\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           1       0.53      0.56      0.54       167\n",
      "           2       0.42      0.50      0.46       196\n",
      "           3       0.56      0.32      0.40        79\n",
      "           4       0.32      0.28      0.30       111\n",
      "\n",
      "   micro avg       0.45      0.45      0.45       553\n",
      "   macro avg       0.45      0.41      0.42       553\n",
      "weighted avg       0.45      0.45      0.44       553\n",
      "\n",
      "0.44665461121157324\n"
     ]
    }
   ],
   "source": [
    "\n",
    "from sklearn.svm import LinearSVC\n",
    "import sklearn.metrics as metrics\n",
    "classifier_rbf = LinearSVC(multi_class=\"ovr\")\n",
    "classifier_rbf.fit(X_train, y_train)\n",
    "prediction_rbf = classifier_rbf.predict(X_test)\n",
    "from sklearn.metrics import classification_report,accuracy_score\n",
    "def prediction_evaluation(model_name,model,test_X,test_Y):\n",
    "    y_pred = model.predict(test_X)\n",
    "    cm = metrics.confusion_matrix(test_Y, y_pred)\n",
    "    print(cm)\n",
    "    print(classification_report(test_Y, y_pred))\n",
    "    print(accuracy_score(test_Y, y_pred))\n",
    "prediction_evaluation(\"SVM\",classifier_rbf,X_test,y_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 123,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "MultinomialNB(alpha=1.0, class_prior=None, fit_prior=True)"
      ]
     },
     "execution_count": 123,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from sklearn.naive_bayes import MultinomialNB\n",
    "clf_NB = MultinomialNB()\n",
    "clf_NB.fit(X_train, y_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 124,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[[ 24 143   0   0]\n",
      " [  7 189   0   0]\n",
      " [  5  74   0   0]\n",
      " [  5 106   0   0]]\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           1       0.59      0.14      0.23       167\n",
      "           2       0.37      0.96      0.53       196\n",
      "           3       0.00      0.00      0.00        79\n",
      "           4       0.00      0.00      0.00       111\n",
      "\n",
      "   micro avg       0.39      0.39      0.39       553\n",
      "   macro avg       0.24      0.28      0.19       553\n",
      "weighted avg       0.31      0.39      0.26       553\n",
      "\n",
      "0.38517179023508136\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/usr/local/lib/python3.7/site-packages/sklearn/metrics/classification.py:1143: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples.\n",
      "  'precision', 'predicted', average, warn_for)\n"
     ]
    }
   ],
   "source": [
    "prediction_evaluation(\"MultinomialNB\",clf_NB,X_test,y_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 125,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "MLPClassifier(activation='relu', alpha=0.001, batch_size='auto', beta_1=0.9,\n",
       "       beta_2=0.999, early_stopping=False, epsilon=1e-08,\n",
       "       hidden_layer_sizes=(500, 200), learning_rate='constant',\n",
       "       learning_rate_init=0.001, max_iter=1000, momentum=0.9,\n",
       "       n_iter_no_change=10, nesterovs_momentum=True, power_t=0.5,\n",
       "       random_state=None, shuffle=True, solver='adam', tol=0.0001,\n",
       "       validation_fraction=0.1, verbose=False, warm_start=False)"
      ]
     },
     "execution_count": 125,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from sklearn.neural_network import MLPClassifier\n",
    "clf_mlp=MLPClassifier(hidden_layer_sizes=(500,200,), activation='relu', solver='adam', max_iter=1000,alpha=0.001)\n",
    "clf_mlp.fit(X_train,y_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 126,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[[ 83  51   4  29]\n",
      " [ 43 110  11  32]\n",
      " [ 15  33  24   7]\n",
      " [ 24  63   1  23]]\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           1       0.50      0.50      0.50       167\n",
      "           2       0.43      0.56      0.49       196\n",
      "           3       0.60      0.30      0.40        79\n",
      "           4       0.25      0.21      0.23       111\n",
      "\n",
      "   micro avg       0.43      0.43      0.43       553\n",
      "   macro avg       0.45      0.39      0.40       553\n",
      "weighted avg       0.44      0.43      0.43       553\n",
      "\n",
      "0.43399638336347196\n"
     ]
    }
   ],
   "source": [
    "prediction_evaluation(\"MLPClassifier\",clf_mlp,X_test,y_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 127,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/usr/local/lib/python3.7/site-packages/sklearn/model_selection/_split.py:2053: FutureWarning: You should specify a value for 'cv' instead of relying on the default value. The default value will change from 3 to 5 in version 0.22.\n",
      "  warnings.warn(CV_WARNING, FutureWarning)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[[ 87  59   2  19]\n",
      " [ 45 119   7  25]\n",
      " [ 17  36  20   6]\n",
      " [ 21  65   1  24]]\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           1       0.51      0.52      0.52       167\n",
      "           2       0.43      0.61      0.50       196\n",
      "           3       0.67      0.25      0.37        79\n",
      "           4       0.32      0.22      0.26       111\n",
      "\n",
      "   micro avg       0.45      0.45      0.45       553\n",
      "   macro avg       0.48      0.40      0.41       553\n",
      "weighted avg       0.47      0.45      0.44       553\n",
      "\n",
      "0.45207956600361665\n"
     ]
    }
   ],
   "source": [
    "from sklearn.linear_model import LogisticRegressionCV\n",
    "clf_lg=LogisticRegressionCV(max_iter=5000,multi_class=\"multinomial\")\n",
    "clf_lg.fit(X_train,y_train)\n",
    "prediction_evaluation(\"logistic\",clf_lg,X_test,y_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 60,
   "metadata": {},
   "outputs": [],
   "source": [
    "data_k=\"now i cant live without you,i'm nothing without you.now i cant live without you, nothing without you.if i go away from you, be away from myself.because its only you,now its only you,you are my life now,peace in me and the pain too,now my love is just you. whats the relation between you and me!that i cant get away for a moment... i live for you everyday,i give every moment of my life to you.there's no moment without you,there's your name in every breath. because its only you,now its only you,you are my life now,peace in me and the pain too,You are my love,cause its only you,because its only you,now my love is just you\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [],
   "source": [
    "data_k=tfidf.fit_transform([data_k])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "  (0, 8)\t0.2750095491084634\n",
      "  (0, 10)\t0.09166984970282113\n",
      "  (0, 12)\t0.18333969940564226\n",
      "  (0, 0)\t0.2750095491084634\n",
      "  (0, 1)\t0.2750095491084634\n",
      "  (0, 13)\t0.5500190982169268\n",
      "  (0, 7)\t0.2750095491084634\n",
      "  (0, 15)\t0.18333969940564226\n",
      "  (0, 14)\t0.18333969940564226\n",
      "  (0, 9)\t0.2750095491084634\n",
      "  (0, 6)\t0.18333969940564226\n",
      "  (0, 16)\t0.09166984970282113\n",
      "  (0, 11)\t0.2750095491084634\n",
      "  (0, 5)\t0.09166984970282113\n",
      "  (0, 4)\t0.18333969940564226\n",
      "  (0, 17)\t0.18333969940564226\n",
      "  (0, 2)\t0.09166984970282113\n",
      "  (0, 3)\t0.09166984970282113\n"
     ]
    }
   ],
   "source": [
    "print(data_k)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 116,
   "metadata": {},
   "outputs": [
    {
     "ename": "ValueError",
     "evalue": "X has 18 features per sample; expecting 6145",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mValueError\u001b[0m                                Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-116-c9de7323c827>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[0;32m----> 1\u001b[0;31m \u001b[0mclf_lg\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mpredict\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mdata_k\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[0;32m/usr/local/lib/python3.7/site-packages/sklearn/linear_model/base.py\u001b[0m in \u001b[0;36mpredict\u001b[0;34m(self, X)\u001b[0m\n\u001b[1;32m    279\u001b[0m             \u001b[0mPredicted\u001b[0m \u001b[0;32mclass\u001b[0m \u001b[0mlabel\u001b[0m \u001b[0mper\u001b[0m \u001b[0msample\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    280\u001b[0m         \"\"\"\n\u001b[0;32m--> 281\u001b[0;31m         \u001b[0mscores\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mdecision_function\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mX\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    282\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0mlen\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mscores\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mshape\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;34m==\u001b[0m \u001b[0;36m1\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    283\u001b[0m             \u001b[0mindices\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m(\u001b[0m\u001b[0mscores\u001b[0m \u001b[0;34m>\u001b[0m \u001b[0;36m0\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mastype\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mnp\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mint\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/usr/local/lib/python3.7/site-packages/sklearn/linear_model/base.py\u001b[0m in \u001b[0;36mdecision_function\u001b[0;34m(self, X)\u001b[0m\n\u001b[1;32m    260\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0mX\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mshape\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;36m1\u001b[0m\u001b[0;34m]\u001b[0m \u001b[0;34m!=\u001b[0m \u001b[0mn_features\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    261\u001b[0m             raise ValueError(\"X has %d features per sample; expecting %d\"\n\u001b[0;32m--> 262\u001b[0;31m                              % (X.shape[1], n_features))\n\u001b[0m\u001b[1;32m    263\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    264\u001b[0m         scores = safe_sparse_dot(X, self.coef_.T,\n",
      "\u001b[0;31mValueError\u001b[0m: X has 18 features per sample; expecting 6145"
     ]
    }
   ],
   "source": [
    "clf_lg.predict(data_k)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 117,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<1x6145 sparse matrix of type '<class 'numpy.float64'>'\n",
       "\twith 69 stored elements in Compressed Sparse Row format>"
      ]
     },
     "execution_count": 117,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "X_test[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 61,
   "metadata": {},
   "outputs": [],
   "source": [
    "data_m = df['lyrics'].values\n",
    "data_m=np.append(data_m,data_k)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 62,
   "metadata": {},
   "outputs": [],
   "source": [
    "z=tfidf.fit_transform(data_m)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 63,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(778, 6145)\n"
     ]
    }
   ],
   "source": [
    "print(z.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 66,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array(['4'], dtype=object)"
      ]
     },
     "execution_count": 66,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "classifier_rbf.predict(z[777])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
